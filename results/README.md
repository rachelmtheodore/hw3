# Q1
The most efficient of the 500 designs was random seed 383 (with the efficiency parameter of 0.15455).The least efficiency of the 500 designs was random seed 213 (with the efficeincy parameter of 0.24210).

When comparing the plots for the best and worst designs (results/design\_best.png and results/design\_worst.png in this repository, respectively), the biggest thing that stands out to me is that the worst design has an extended period in which no stimuli are present (no stimulus is presented for volumes ~80-120), whereas the best design has far fewer extended intervals without stimuli. The second thing that stands out is that in the best design, stimulus type seem to be a bit more concentrated in time, in that a period of predominately one condition (shown as green, for example) is present, flanked by periods of a different stimulus type (i.e., the red and blue). For the worst design, there's a lot more condition variability in a given time period.

# Q2
The most efficient design after 5000 iterations of make\_random\_timing.py (implemented using scripts/mrt\_timing_02.sh was random seed 4135 (efficiency parameter = 0.17685). At first I was confused becasue the resulting .png didn't show functions separated by condition (or at least it isn't marked in this color as was done before), but I gather that's because the .1D input here was timings in a single vector (as opposed to three vectors for the exercise in Q1. Assuming I didn't mess up making this figure, the biggest things that stands out is the more regular spacing of stimuli compared to the times generated by RSFgen, which isn't suprising given that the make\_random\_timing script specified regular spacing (through contrainsts on min/max ISIs). The other thing that stands out is that there is decreased colinarity of the peaks on the ordinate; they are not all at the maximum (as they were for timings generated by RSFgen). I think that the 1/2/3 on the ordinate refers to conditions A/B/C, but I'm not entirely clear on this...

# Q3
When adding the -max_consec 1 argument to the script used in #2 (copied to mrt\_timing_02.sh), the most efficient run was for seed 1316 (efficiency parameter = 0.20025). The main difference in the resulting plot compared to that generate with RSFgen is with the new one, there aren't consecutive time periods in which the same stimulus is presented, at least if that is what the 1/2/3 on the ordinate is showing (i.e., peaks @ 1 = condition 1 stimulus, peaks @ 2 = condition 2 stimulus). The best design from RSFgen had multiple time regions in which stimuli from the same condition were repeated multiple times without any other intervening stimulus condition.

# Q4
The lowest efficiency parameter was generated by simulations using RSFgen, but colinearity was most decreased when ISIs were constrained to be more consistent. I don't know enough to determine whether a difference in the efficiency parameter of ~.15 and ~.20 is meaningful. But assuming they are equivalent, then it seems that constraining ISI to be consistent using the make\_random\_timing script will lead to producing better overall designs.

# Q5

Overall, longer block durations were associated with higher (i.e., worse) efficiency parameters; this was most pronounced for the difference between block durations of 100 and 50 s. For the shortest block duration (20 s), the efficiency for the two contrasts seems quite equivlaent (0.0308 vs. 0.0312), and to be honest also quite equivalent for the 50 s block durations (0.0298 vs. 0.0325). I don't know enough about this parameter to know whether a difference of a few hundredths matters. For the 100 s blocks, the efficiency of the A-B constrast was ~half that of the A-C contrast (0.0513 vs. 0.0894). I'm guessing that this is because the the denominator for calculating the characteristic frequency is higher in the latter case.

# Q6

Overall, efficiency values increased (i.e., got worse) as the -polort parameter increased. Inspection of the GLT matrix shows that increasing the -polort parameter led to increased 0s before the contrasts specifying the condition comparison. It's clear that this is changing the underlying regression model, but I'm not clear as to how specifically. (I'm going to read up further on this now, and also run this for the 20 s block to see if that helps me figure it out.)

# Q7

For contrasting two conditions, I'd say go with a block design, because this would drive the BOLD reponse to peak value in each block, maximizing contrasts across blocks. In the efficiency simulations for the 20 second blocks, these values were really good (i.e., low), so if that holds for two blocks, then this seems a more efficienct design compared to the event-related method (based on efficiency values from the RSFgen simulations in Q1, for example).

# Q8

For contrasting seven conditions, I'd say go with an event-related design. Efficiency will vary by contrast (e.g., contrast 1-2 vs. contrast 1-7) to a noticable degree in a block design when more blocks are involved. I'd need to know more about the overall design; if these are seven levels of one independent variable, then I'm assuming any main effect would need to explicated by a host of pair-wise comparisons, and I'm not sure how corrections for that are considered in terms of the contrast/condition comparisons. But the simulations performed for Q1 - Q3 suggest that an optimized event-related design would be more efficient than a block design when seven conditions are involved.